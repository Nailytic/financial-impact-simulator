import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import datetime
import calendar
from statsmodels.tsa.seasonal import seasonal_decompose
from scipy.stats import pearsonr
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n de la p√°gina
st.set_page_config(page_title="Dashboard de Productividad y Bienestar Laboral", 
                   layout="wide", 
                   initial_sidebar_state="expanded")

# Funciones para generar y procesar datos de ejemplo
def generate_sample_data(n_employees=100, days=90):
    """
    Genera datos sint√©ticos de productividad y bienestar laboral para demostraci√≥n
    """
    np.random.seed(42)
    
    # Fechas de los √∫ltimos d√≠as
    end_date = datetime.datetime.now().date()
    start_date = end_date - datetime.timedelta(days=days-1)
    dates = [start_date + datetime.timedelta(days=i) for i in range(days)]
    
    # IDs de empleados
    employee_ids = [f"EMP{i:03d}" for i in range(1, n_employees+1)]
    
    # Departamentos
    departments = ['Desarrollo', 'Marketing', 'Ventas', 'Soporte', 'Recursos Humanos', 'Finanzas']
    employee_departments = np.random.choice(departments, size=n_employees)
    
    # Roles
    roles = {
        'Desarrollo': ['Desarrollador Senior', 'Desarrollador Junior', 'Arquitecto', 'QA', 'DevOps'],
        'Marketing': ['Especialista SEO', 'Dise√±ador', 'Especialista en Redes Sociales', 'Content Manager'],
        'Ventas': ['Account Manager', 'Sales Representative', 'Sales Manager'],
        'Soporte': ['Soporte T√©cnico', 'Customer Success', 'Technical Writer'],
        'Recursos Humanos': ['HR Specialist', 'Recruiter', 'HR Manager'],
        'Finanzas': ['Accountant', 'Financial Analyst', 'Controller']
    }
    
    employee_roles = [np.random.choice(roles[dept]) for dept in employee_departments]
    
    # A√±os de experiencia
    experience_years = np.random.randint(1, 15, size=n_employees)
    
    # Crear dataframe base de empleados
    employees_df = pd.DataFrame({
        'employee_id': employee_ids,
        'department': employee_departments,
        'role': employee_roles,
        'experience_years': experience_years
    })
    
    # Crear patrones base para cada empleado
    employee_patterns = {}
    for emp_id in employee_ids:
        # Productividad base (var√≠a por empleado)
        base_productivity = np.random.normal(70, 15)
        # Nivel de estr√©s base
        base_stress = np.random.normal(40, 15)
        # Satisfacci√≥n base
        base_satisfaction = np.random.normal(75, 15)
        # Horas de trabajo base
        base_work_hours = np.random.normal(8, 1)
        
        employee_patterns[emp_id] = {
            'base_productivity': base_productivity,
            'base_stress': base_stress,
            'base_satisfaction': base_satisfaction,
            'base_work_hours': base_work_hours
        }
    
    # Crear dataframe diario
    data = []
    
    for date in dates:
        # Factores del d√≠a (afecta a todos los empleados)
        day_factor = np.random.normal(1, 0.05)  # Factor aleatorio diario
        day_of_week = date.weekday()  # 0=Lunes, 6=Domingo
        
        # Patr√≥n semanal (menor productividad en lunes, mayor el mi√©rcoles-jueves, baja el viernes)
        weekday_productivity_factor = {
            0: 0.95,  # Lunes
            1: 1.0,   # Martes
            2: 1.05,  # Mi√©rcoles
            3: 1.05,  # Jueves
            4: 0.97,  # Viernes
            5: 0.85,  # S√°bado (si trabajan)
            6: 0.8,   # Domingo (si trabajan)
        }
        
        # Patr√≥n estacional (mes)
        month = date.month
        # Menor productividad en verano y cerca de navidad
        if month in [7, 8, 12]:
            seasonal_factor = 0.95
        elif month in [1, 9]:  # Mayor despu√©s de vacaciones
            seasonal_factor = 1.05
        else:
            seasonal_factor = 1.0
            
        # Verificar si es fin de semana
        is_weekend = day_of_week >= 5
        
        for idx, employee in employees_df.iterrows():
            emp_id = employee['employee_id']
            
            # Si es fin de semana, la mayor√≠a no trabaja
            if is_weekend and np.random.random() > 0.2:  # Solo 20% trabaja en fin de semana
                continue
                
            patterns = employee_patterns[emp_id]
            
            # Calcular m√©tricas diarias
            
            # Productividad (tareas completadas/calidad)
            productivity = patterns['base_productivity'] * day_factor * weekday_productivity_factor[day_of_week] * seasonal_factor
            productivity = np.clip(productivity + np.random.normal(0, 5), 0, 100)
            
            # Horas trabajadas
            work_hours = patterns['base_work_hours']
            # A√±adir variaci√≥n
            if is_weekend:
                work_hours *= 0.8  # Menos horas en fin de semana
            work_hours = np.clip(work_hours + np.random.normal(0, 0.5), 4, 12)
            
            # Tiempo en reuniones (horas)
            meeting_hours = work_hours * np.random.uniform(0.1, 0.3)
            if day_of_week == 0:  # M√°s reuniones los lunes
                meeting_hours *= 1.5
            meeting_hours = np.clip(meeting_hours, 0, work_hours * 0.7)
            
            # Concentraci√≥n (tiempo productivo)
            focus_hours = work_hours - meeting_hours - np.random.uniform(0.5, 1.5)  # Tiempo perdido
            focus_hours = np.clip(focus_hours, 0, work_hours)
            
            # Nivel de estr√©s
            stress_level = patterns['base_stress']
            # Factores que aumentan el estr√©s
            stress_factors = 1.0
            if work_hours > 9:  # Sobrecarga
                stress_factors += (work_hours - 9) * 0.15
            if meeting_hours / work_hours > 0.4:  # Muchas reuniones
                stress_factors += 0.2
            if day_of_week == 4:  # Viernes, entregas
                stress_factors += 0.1
                
            stress_level *= stress_factors
            stress_level = np.clip(stress_level + np.random.normal(0, 5), 0, 100)
            
            # Satisfacci√≥n
            satisfaction = patterns['base_satisfaction']
            # Factores que afectan la satisfacci√≥n
            if stress_level > 70:  # Alto estr√©s reduce satisfacci√≥n
                satisfaction *= 0.85
            if productivity > 80:  # Alta productividad aumenta satisfacci√≥n
                satisfaction *= 1.1
            if focus_hours / work_hours < 0.4:  # Poco tiempo productivo
                satisfaction *= 0.9
                
            satisfaction = np.clip(satisfaction + np.random.normal(0, 3), 0, 100)
            
            # Equilibrio trabajo-vida (Work-Life Balance)
            if work_hours <= 8:
                work_life_balance = np.random.uniform(70, 90)
            else:
                # Disminuye con horas extras
                work_life_balance = np.random.uniform(50, 80) - (work_hours - 8) * 7
                
            work_life_balance = np.clip(work_life_balance + np.random.normal(0, 5), 0, 100)
            
            # Compromiso (Engagement)
            engagement = (satisfaction * 0.5 + productivity * 0.3 + (100 - stress_level) * 0.2)
            engagement = np.clip(engagement + np.random.normal(0, 5), 0, 100)
            
            # Colaboraci√≥n (interacciones con colegas)
            collaboration = meeting_hours * np.random.uniform(10, 15)
            collaboration = np.clip(collaboration + np.random.normal(0, 10), 0, 100)
            
            # Agregar registro
            data.append({
                'date': date,
                'employee_id': emp_id,
                'department': employee['department'],
                'role': employee['role'],
                'experience_years': employee['experience_years'],
                'productivity': round(productivity, 1),
                'work_hours': round(work_hours, 1),
                'meeting_hours': round(meeting_hours, 1),
                'focus_hours': round(focus_hours, 1),
                'stress_level': round(stress_level, 1),
                'satisfaction': round(satisfaction, 1),
                'work_life_balance': round(work_life_balance, 1),
                'engagement': round(engagement, 1),
                'collaboration': round(collaboration, 1)
            })
    
    # Crear DataFrame
    df = pd.DataFrame(data)
    
    # A√±adir eventos aleatorios (simulando eventos que afectan a la productividad)
    # 1. Sprint deadlines (aumenta estr√©s y productividad)
    sprint_days = [start_date + datetime.timedelta(days=i) for i in range(days) if (i+1) % 14 == 0]
    for sprint_day in sprint_days:
        # Afecta principalmente a desarrolladores
        dev_df = df[(df['date'] == sprint_day) & (df['department'] == 'Desarrollo')]
        for idx in dev_df.index:
            df.loc[idx, 'stress_level'] = min(100, df.loc[idx, 'stress_level'] * 1.3)
            df.loc[idx, 'productivity'] = min(100, df.loc[idx, 'productivity'] * 1.15)
            df.loc[idx, 'work_hours'] = min(12, df.loc[idx, 'work_hours'] + 1.5)
            df.loc[idx, 'focus_hours'] = min(df.loc[idx, 'work_hours'], df.loc[idx, 'focus_hours'] * 1.2)
    
    # 2. Lanzamiento de producto (afecta a varios departamentos)
    launch_day = start_date + datetime.timedelta(days=days//2)
    launch_period = [launch_day - datetime.timedelta(days=i) for i in range(5)]
    affected_depts = ['Desarrollo', 'Marketing', 'Ventas']
    for day in launch_period:
        affected_df = df[(df['date'] == day) & (df['department'].isin(affected_depts))]
        for idx in affected_df.index:
            # Aumenta estr√©s, horas y productividad
            df.loc[idx, 'stress_level'] = min(100, df.loc[idx, 'stress_level'] * 1.25)
            df.loc[idx, 'work_hours'] = min(12, df.loc[idx, 'work_hours'] + 2)
            df.loc[idx, 'meeting_hours'] = min(df.loc[idx, 'work_hours'] * 0.6, df.loc[idx, 'meeting_hours'] * 1.5)
            df.loc[idx, 'focus_hours'] = max(0, df.loc[idx, 'work_hours'] - df.loc[idx, 'meeting_hours'] - 1)
            df.loc[idx, 'productivity'] = min(100, df.loc[idx, 'productivity'] * 1.1)
            df.loc[idx, 'work_life_balance'] = max(0, df.loc[idx, 'work_life_balance'] * 0.8)
    
    # 3. Iniciativa de bienestar (mejora satisfacci√≥n y equilibrio)
    wellness_start = start_date + datetime.timedelta(days=days//4)
    wellness_period = [wellness_start + datetime.timedelta(days=i) for i in range(14)]
    for day in wellness_period:
        wellness_df = df[df['date'] == day]
        for idx in wellness_df.index:
            if np.random.random() < 0.7:  # 70% participaci√≥n
                df.loc[idx, 'stress_level'] = max(0, df.loc[idx, 'stress_level'] * 0.9)
                df.loc[idx, 'satisfaction'] = min(100, df.loc[idx, 'satisfaction'] * 1.1)
                df.loc[idx, 'work_life_balance'] = min(100, df.loc[idx, 'work_life_balance'] * 1.15)
    
    return df

def identify_work_profiles(df):
    """
    Identifica perfiles de trabajo basados en patrones de productividad y bienestar
    """
    # Agregaci√≥n por empleado
    emp_metrics = df.groupby('employee_id').agg({
        'productivity': 'mean',
        'work_hours': 'mean',
        'meeting_hours': 'mean',
        'focus_hours': 'mean',
        'stress_level': 'mean',
        'satisfaction': 'mean',
        'work_life_balance': 'mean',
        'engagement': 'mean',
        'collaboration': 'mean'
    }).reset_index()
    
    # A√±adir m√©tricas adicionales
    emp_metrics['focus_ratio'] = emp_metrics['focus_hours'] / emp_metrics['work_hours']
    emp_metrics['meeting_ratio'] = emp_metrics['meeting_hours'] / emp_metrics['work_hours']
    
    # Estandarizar datos para clustering
    features = ['productivity', 'work_hours', 'focus_ratio', 'meeting_ratio', 
                'stress_level', 'satisfaction', 'work_life_balance', 'engagement']
    
    X = emp_metrics[features].copy()
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # Determinar n√∫mero √≥ptimo de clusters
    inertia = []
    for k in range(2, 8):
        kmeans = KMeans(n_clusters=k, random_state=42)
        kmeans.fit(X_scaled)
        inertia.append(kmeans.inertia_)
    
    # Utilizamos 4 clusters (simplificado para este ejemplo)
    k = 4
    kmeans = KMeans(n_clusters=k, random_state=42)
    emp_metrics['work_profile'] = kmeans.fit_predict(X_scaled)
    
    # Analizar caracter√≠sticas de cada perfil
    profile_descriptions = {}
    
    for profile in range(k):
        profile_data = emp_metrics[emp_metrics['work_profile'] == profile]
        
        # Calcular caracter√≠sticas promedio
        profile_descriptions[profile] = {
            'count': len(profile_data),
            'avg_productivity': profile_data['productivity'].mean(),
            'avg_work_hours': profile_data['work_hours'].mean(),
            'avg_focus_ratio': profile_data['focus_ratio'].mean(),
            'avg_meeting_ratio': profile_data['meeting_ratio'].mean(),
            'avg_stress': profile_data['stress_level'].mean(),
            'avg_satisfaction': profile_data['satisfaction'].mean(),
            'avg_work_life_balance': profile_data['work_life_balance'].mean(),
            'avg_engagement': profile_data['engagement'].mean()
        }
    
    # Asignar nombres a los perfiles basados en caracter√≠sticas
    profile_names = {}
    
    for profile, stats in profile_descriptions.items():
        # L√≥gica para nombrar perfiles
        if stats['avg_productivity'] > 75 and stats['avg_work_life_balance'] > 70:
            profile_names[profile] = "Equilibrado de Alto Rendimiento"
        elif stats['avg_productivity'] > 75 and stats['avg_stress'] > 60:
            profile_names[profile] = "Alto Rendimiento Estresado"
        elif stats['avg_meeting_ratio'] > 0.25 and stats['avg_collaboration'] > 60:
            profile_names[profile] = "Colaborador Extendido"
        elif stats['avg_focus_ratio'] > 0.7:
            profile_names[profile] = "Trabajador Concentrado"
        else:
            profile_names[profile] = f"Perfil {profile+1}"
    
    # A√±adir nombre del perfil al dataframe de empleados
    emp_metrics['profile_name'] = emp_metrics['work_profile'].map(profile_names)
    
    # A√±adir informaci√≥n del departamento
    dept_info = df.groupby('employee_id')['department'].first().reset_index()
    emp_metrics = emp_metrics.merge(dept_info, on='employee_id')
    
    # Guardar centroides
    centroids = pd.DataFrame(
        scaler.inverse_transform(kmeans.cluster_centers_), 
        columns=features
    )
    centroids['profile'] = range(k)
    centroids['profile_name'] = centroids['profile'].map(profile_names)
    
    return emp_metrics, centroids, profile_names

def analyze_burnout_risk(df):
    """
    Analiza riesgo de burnout basado en m√©tricas de estr√©s, 
    satisfacci√≥n y equilibrio trabajo-vida
    """
    # Agregaci√≥n por empleado
    emp_metrics = df.groupby('employee_id').agg({
        'productivity': 'mean',
        'work_hours': 'mean',
        'stress_level': 'mean',
        'satisfaction': 'mean',
        'work_life_balance': 'mean',
        'engagement': 'mean',
        'department': 'first',
        'role': 'first',
        'experience_years': 'first'
    }).reset_index()
    
    # Analizar tendencia de estr√©s en las √∫ltimas 2 semanas
    last_2w = df[df['date'] >= df['date'].max() - datetime.timedelta(days=14)]
    stress_trend = last_2w.groupby(['employee_id', 'date'])['stress_level'].mean().reset_index()
    
    # Calcular pendiente de estr√©s
    stress_slopes = {}
    for emp in stress_trend['employee_id'].unique():
        emp_data = stress_trend[stress_trend['employee_id'] == emp].sort_values('date')
        if len(emp_data) >= 7:  # Al menos una semana de datos
            x = (emp_data['date'] - emp_data['date'].min()).dt.days.values
            y = emp_data['stress_level'].values
            slope = np.polyfit(x, y, 1)[0]
            stress_slopes[emp] = slope
    
    # A√±adir pendiente al dataframe
    emp_metrics['stress_trend'] = emp_metrics['employee_id'].map(stress_slopes).fillna(0)
    
    # Calcular riesgo de burnout
    emp_metrics['burnout_risk_score'] = (
        emp_metrics['stress_level'] * 0.35 +
        (100 - emp_metrics['satisfaction']) * 0.25 +
        (100 - emp_metrics['work_life_balance']) * 0.25 +
        np.clip(emp_metrics['stress_trend'] * 20, 0, 15) +  # Factor de tendencia
        np.clip((emp_metrics['work_hours'] - 8) * 3, 0, 15)  # Factor de sobrecarga
    )
    
    # Normalizar score a 0-100
    emp_metrics['burnout_risk_score'] = np.clip(emp_metrics['burnout_risk_score'], 0, 100)
    
    # Categorizar riesgo
    conditions = [
        (emp_metrics['burnout_risk_score'] < 30),
        (emp_metrics['burnout_risk_score'] < 50),
        (emp_metrics['burnout_risk_score'] < 70),
        (emp_metrics['burnout_risk_score'] >= 70)
    ]
    risk_categories = ['Bajo', 'Moderado', 'Alto', 'Cr√≠tico']
    emp_metrics['burnout_risk'] = np.select(conditions, risk_categories)
    
    # An√°lisis de factores contribuyentes
    emp_metrics['long_hours_factor'] = np.clip((emp_metrics['work_hours'] - 8.5) * 10, 0, 100)
    emp_metrics['stress_factor'] = emp_metrics['stress_level']
    emp_metrics['satisfaction_factor'] = 100 - emp_metrics['satisfaction']
    emp_metrics['balance_factor'] = 100 - emp_metrics['work_life_balance']
    
    # Identificar factor principal para cada empleado
    factors = ['long_hours_factor', 'stress_factor', 'satisfaction_factor', 'balance_factor']
    emp_metrics['primary_factor'] = emp_metrics[factors].idxmax(axis=1)
    emp_metrics['primary_factor'] = emp_metrics['primary_factor'].map({
        'long_hours_factor': 'Horas Extendidas',
        'stress_factor': 'Estr√©s Elevado',
        'satisfaction_factor': 'Baja Satisfacci√≥n',
        'balance_factor': 'Desequilibrio Trabajo-Vida'
    })
    
    return emp_metrics

def analyze_department_metrics(df):
    """
    Analiza m√©tricas de productividad y bienestar por departamento
    """
    # M√©trica agregadas por departamento
    dept_metrics = df.groupby('department').agg({
        'productivity': 'mean',
        'work_hours': 'mean',
        'meeting_hours': 'mean',
        'focus_hours': 'mean',
        'stress_level': 'mean',
        'satisfaction': 'mean',
        'work_life_balance': 'mean',
        'engagement': 'mean',
        'collaboration': 'mean',
        'employee_id': 'nunique'
    }).reset_index()
    
    # Renombrar columna para claridad
    dept_metrics = dept_metrics.rename(columns={'employee_id': 'employee_count'})
    
    # Calcular ratios adicionales
    dept_metrics['focus_ratio'] = dept_metrics['focus_hours'] / dept_metrics['work_hours']
    dept_metrics['meeting_ratio'] = dept_metrics['meeting_hours'] / dept_metrics['work_hours']
    
    # An√°lisis de tendencias por departamento
    dept_trends = df.groupby(['department', 'date']).agg({
        'productivity': 'mean',
        'stress_level': 'mean',
        'satisfaction': 'mean'
    }).reset_index()
    
    # Calcular pendientes para cada departamento (tendencias)
    dept_slopes = {}
    for dept in dept_trends['department'].unique():
        dept_data = dept_trends[dept_trends['department'] == dept].sort_values('date')
        x = (dept_data['date'] - dept_data['date'].min()).dt.days.values
        
        # Pendientes para cada m√©trica
        prod_slope = np.polyfit(x, dept_data['productivity'].values, 1)[0]
        stress_slope = np.polyfit(x, dept_data['stress_level'].values, 1)[0]
        sat_slope = np.polyfit(x, dept_data['satisfaction'].values, 1)[0]
        
        dept_slopes[dept] = {
            'productivity_trend': prod_slope * 30,  # Escalado a cambio mensual
            'stress_trend': stress_slope * 30,
            'satisfaction_trend': sat_slope * 30
        }
    
    # A√±adir tendencias al dataframe
    for metric in ['productivity_trend', 'stress_trend', 'satisfaction_trend']:
        dept_metrics[metric] = dept_metrics['department'].map(
            {dept: slopes[metric] for dept, slopes in dept_slopes.items()}
        )
    
    return dept_metrics, dept_trends

def analyze_optimal_conditions(df):
    """
    Identifica condiciones √≥ptimas para productividad y bienestar
    """
    # An√°lisis de correlaciones
    correlation_data = df[['productivity', 'work_hours', 'meeting_hours', 'focus_hours', 
                           'stress_level', 'satisfaction', 'work_life_balance', 
                           'engagement', 'collaboration']].copy()
    
    corr_matrix = correlation_data.corr()
    
    # An√°lisis de condiciones √≥ptimas para productividad
    productivity_factors = []
    
    # Relaci√≥n entre horas de concentraci√≥n y productividad
    focus_data = df.groupby('employee_id').agg({
        'focus_hours': 'mean',
        'productivity': 'mean'
    }).reset_index()
    
    focus_corr, _ = pearsonr(focus_data['focus_hours'], focus_data['productivity'])
    productivity_factors.append({
        'factor': 'Horas de Concentraci√≥n',
        'correlation': focus_corr,
        'optimal_range': f"{focus_data.loc[focus_data['productivity'] > focus_data['productivity'].quantile(0.75), 'focus_hours'].mean():.1f} - {focus_data.loc[focus_data['productivity'] > focus_data['productivity'].quantile(0.9), 'focus_hours'].mean():.1f} horas"
    })
    
    # Relaci√≥n entre reuniones y productividad
    meeting_data = df.groupby('employee_id').agg({
        'meeting_ratio': lambda x: (df.loc[x.index, 'meeting_hours'] / df.loc[x.index, 'work_hours']).mean(),
        'productivity': 'mean'
    }).reset_index()
    
    meeting_corr, _ = pearsonr(meeting_data['meeting_ratio'], meeting_data['productivity'])
    productivity_factors.append({
        'factor': 'Ratio de Reuniones',
        'correlation': meeting_corr,
        'optimal_range': f"{meeting_data.loc[meeting_data['productivity'] > meeting_data['productivity'].quantile(0.75), 'meeting_ratio'].mean()*100:.1f}% - {meeting_data.loc[meeting_data['productivity'] > meeting_data['productivity'].quantile(0.9), 'meeting_ratio'].mean()*100:.1f}% del tiempo"
    })
    
    # Relaci√≥n entre estr√©s y productividad
    stress_data = df.groupby('employee_id').agg({
        'stress_level': 'mean',
        'productivity': 'mean'
    }).reset_index()
    
    stress_corr, _ = pearsonr(stress_data['stress_level'], stress_data['productivity'])
    productivity_factors.append({
        'factor': 'Nivel de Estr√©s',
        'correlation': stress_corr,
        'optimal_range': f"{stress_data.loc[stress_data['productivity'] > stress_data['productivity'].quantile(0.75), 'stress_level'].mean():.1f} - {stress_data.loc[stress_data['productivity'] > stress_data['productivity'].quantile(0.9), 'stress_level'].mean():.1f}%"
    })
    
    # An√°lisis de condiciones √≥ptimas para satisfacci√≥n
    satisfaction_factors = []
    
    # Relaci√≥n entre horas de trabajo y satisfacci√≥n
    hours_data = df.groupby('employee_id').agg({
        'work_hours': 'mean',
        'satisfaction': 'mean'
    }).reset_index()
    
    hours_corr, _ = pearsonr(hours_data['work_hours'], hours_data['satisfaction'])
    satisfaction_factors.append({
        'factor': 'Horas de Trabajo',
        'correlation': hours_corr,
        'optimal_range': f"{hours_data.loc[hours_data['satisfaction'] > hours_data['satisfaction'].quantile(0.75), 'work_hours'].mean():.1f} - {hours_data.loc[hours_data['satisfaction'] > hours_data['satisfaction'].quantile(0.9), 'work_hours'].mean():.1f} horas"
    })
    
    # Relaci√≥n entre equilibrio trabajo-vida y satisfacci√≥n
    balance_data = df.groupby('employee_id').agg({
        'work_life_balance': 'mean',
        'satisfaction': 'mean'
    }).reset_index()
    
    balance_corr, _ = pearsonr(balance_data['work_life_balance'], balance_data['satisfaction'])
    satisfaction_factors.append({
        'factor': 'Equilibrio Trabajo-Vida',
        'correlation': balance_corr,
        'optimal_range': f"{balance_data.loc[balance_data['satisfaction'] > balance_data['satisfaction'].quantile(0.75), 'work_life_balance'].mean():.1f}+ puntos"
    })
    
    return corr_matrix, productivity_factors, satisfaction_factors

# Funci√≥n para generar visualizaciones
def create_dashboard_visualizations(df, work_profiles, burnout_risk, dept_metrics, corr_matrix):
    """
    Crea visualizaciones para el dashboard
    """
    visualizations = {}
    
    # 1. Matriz de correlaci√≥n
    plt.figure(figsize=(10, 8))
    mask = np.triu(np.ones_like(corr_matrix))
    sns.heatmap(corr_matrix, mask=mask, annot=True, fmt=".2f", cmap="coolwarm", 
                vmin=-1, vmax=1, cbar_kws={"shrink": .8})
    plt.title("Correlaciones entre M√©tricas de Productividad y Bienestar", fontsize=14)
    plt.tight_layout()
    
    # Guardar figura
    fig_correlation = plt.gcf()
    visualizations['correlation_matrix'] = fig_correlation
    
    # 2. Dispersi√≥n de Productividad vs. Bienestar con perfiles
    productivity_wellbeing_scatter = px.scatter(
        work_profiles, 
        x='productivity', 
        y='work_life_balance',
        size='work_hours',
        color='profile_name',
        hover_name='employee_id',
        hover_data=['department', 'satisfaction', 'stress_level'],
        title='Relaci√≥n entre Productividad y Bienestar por Perfil de Trabajo',
        labels={
            'productivity': 'Productividad',
            'work_life_balance': 'Equilibrio Trabajo-Vida',
            'work_hours': 'Horas de Trabajo',
            'profile_name': 'Perfil de Trabajo'
        }
    )
    
    productivity_wellbeing_scatter.update_layout(
        height=600,
        xaxis=dict(range=[0, 100]),
        yaxis=dict(range=[0, 100]),
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=-0.2,
            xanchor="center",
            x=0.5
        )
    )
    
    visualizations['productivity_wellbeing_scatter'] = productivity_wellbeing_scatter
    
    # 3. Mapa de calor de riesgo de burnout por departamento
    burnout_by_dept = burnout_risk.groupby('department').agg({
        'burnout_risk_score': 'mean',
        'employee_id': 'count'
    }).reset_index()
    
    burnout_by_dept = burnout_by_dept.rename(columns={'employee_id': 'employee_count'})
    burnout_by_dept = burnout_by_dept.sort_values('burnout_risk_score', ascending=False)
    
    burnout_heatmap = px.bar(
        burnout_by_dept,
        x='department',
        y='employee_count',
        color='burnout_risk_score',
        color_continuous_scale=[(0, 'green'), (0.4, 'yellow'), (0.7, 'orange'), (1, 'red')],
        title='Riesgo de Burnout por Departamento',
        labels={
            'department': 'Departamento',
            'employee_count': 'N√∫mero de Empleados',
            'burnout_risk_score': 'Riesgo de Burnout'
        }
    )
    
    burnout_heatmap.update_layout(
        height=400,
        coloraxis_colorbar=dict(
            title="Riesgo",
            tickvals=[20, 40, 60, 80],
            ticktext=["Bajo", "Moderado", "Alto", "Cr√≠tico"]
        )
    )
    
    visualizations['burnout_heatmap'] = burnout_heatmap
    
    # 4. Radar chart de perfiles de trabajo
    profile_metrics = work_profiles.groupby('profile_name').agg({
        'productivity': 'mean',
        'work_hours': 'mean',
        'focus_ratio': 'mean',
        'stress_level': 'mean',
        'satisfaction': 'mean',
        'work_life_balance': 'mean',
        'engagement': 'mean',
        'collaboration': 'mean'
    }).reset_index()
    
    # Normalizar datos para radar chart
    metrics_to_normalize = ['productivity', 'work_hours', 'focus_ratio', 'stress_level', 
                           'satisfaction', 'work_life_balance', 'engagement', 'collaboration']
    
    for metric in metrics_to_normalize:
        max_val = profile_metrics[metric].max()
        min_val = profile_metrics[metric].min()
        profile_metrics[f'{metric}_norm'] = (profile_metrics[metric] - min_val) / (max_val - min_val)
    
    # Crear radar chart
    fig_radar = go.Figure()
    
    categories = ['Productividad', 'Horas de Trabajo', 'Ratio de Concentraci√≥n', 'Nivel de Estr√©s',
                 'Satisfacci√≥n', 'Equilibrio Trabajo-Vida', 'Compromiso', 'Colaboraci√≥n']
    
    for i, profile in enumerate(profile_metrics['profile_name']):
        row = profile_metrics[profile_metrics['profile_name'] == profile]
        values = [
            row['productivity_norm'].values[0],
            row['work_hours_norm'].values[0],
            row['focus_ratio_norm'].values[0],
            row['stress_level_norm'].values[0],
            row['satisfaction_norm'].values[0],
            row['work_life_balance_norm'].values[0],
            row['engagement_norm'].values[0],
            row['collaboration_norm'].values[0]
        ]
        
        fig_radar.add_trace(go.Scatterpolar(
            r=values,
            theta=categories,
            fill='toself',
            name=profile
        ))
    
    fig_radar.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, 1]
            )
        ),
        title='Comparaci√≥n de Perfiles de Trabajo',
        height=500
    )
    
    visualizations['profile_radar'] = fig_radar
    
    # 5. Gr√°fico de tendencias por departamento
    dept_metrics_sorted = dept_metrics.sort_values('productivity', ascending=False)
    
    # Crear figura con subplots
    dept_trends = make_subplots(rows=3, cols=1, 
                               subplot_titles=("Productividad por Departamento", 
                                               "Satisfacci√≥n por Departamento", 
                                               "Estr√©s por Departamento"),
                               vertical_spacing=0.1,
                               shared_xaxes=True)
    
    # A√±adir barras para m√©tricas actuales
    dept_trends.add_trace(
        go.Bar(
            x=dept_metrics_sorted['department'],
            y=dept_metrics_sorted['productivity'],
            text=dept_metrics_sorted['productivity'].round(1),
            textposition='auto',
            name='Productividad Actual',
            marker_color='royalblue'
        ),
        row=1, col=1
    )
    
    dept_trends.add_trace(
        go.Bar(
            x=dept_metrics_sorted['department'],
            y=dept_metrics_sorted['satisfaction'],
            text=dept_metrics_sorted['satisfaction'].round(1),
            textposition='auto',
            name='Satisfacci√≥n Actual',
            marker_color='mediumseagreen'
        ),
        row=2, col=1
    )
    
    dept_trends.add_trace(
        go.Bar(
            x=dept_metrics_sorted['department'],
            y=dept_metrics_sorted['stress_level'],
            text=dept_metrics_sorted['stress_level'].round(1),
            textposition='auto',
            name='Estr√©s Actual',
            marker_color='salmon'
        ),
        row=3, col=1
    )
    
    # A√±adir indicadores de tendencia
    for i, dept in enumerate(dept_metrics_sorted['department']):
        row_data = dept_metrics_sorted[dept_metrics_sorted['department'] == dept]
        
        # Productividad
        trend = row_data['productivity_trend'].values[0]
        if abs(trend) > 0.5:  # Solo mostrar tendencias significativas
            icon = "‚ñ≥" if trend > 0 else "‚ñΩ"
            dept_trends.add_annotation(
                x=dept, y=row_data['productivity'].values[0] + 2,
                text=f"{icon} {abs(trend):.1f}",
                showarrow=False,
                font=dict(color="green" if trend > 0 else "red"),
                row=1, col=1
            )
        
        # Satisfacci√≥n
        trend = row_data['satisfaction_trend'].values[0]
        if abs(trend) > 0.5:  # Solo mostrar tendencias significativas
            icon = "‚ñ≥" if trend > 0 else "‚ñΩ"
            dept_trends.add_annotation(
                x=dept, y=row_data['satisfaction'].values[0] + 2,
                text=f"{icon} {abs(trend):.1f}",
                showarrow=False,
                font=dict(color="green" if trend > 0 else "red"),
                row=2, col=1
            )
        
        # Estr√©s
        trend = row_data['stress_trend'].values[0]
        if abs(trend) > 0.5:  # Solo mostrar tendencias significativas
            icon = "‚ñ≥" if trend > 0 else "‚ñΩ"
            dept_trends.add_annotation(
                x=dept, y=row_data['stress_level'].values[0] + 2,
                text=f"{icon} {abs(trend):.1f}",
                showarrow=False,
                font=dict(color="red" if trend > 0 else "green"),
                row=3, col=1
            )
    
    dept_trends.update_layout(
        height=700,
        showlegend=False,
        title_text="M√©tricas por Departamento con Tendencias Mensuales"
    )
    
    visualizations['dept_trends'] = dept_trends
    
    # 6. Diagrama de flujo focus-productivity
    focus_prod_data = df.groupby('employee_id').agg({
        'focus_hours': 'mean',
        'productivity': 'mean',
        'department': 'first'
    }).reset_index()
    
    focus_flow = px.scatter(
        focus_prod_data,
        x='focus_hours',
        y='productivity',
        color='department',
        trendline='ols',
        title='Relaci√≥n entre Horas de Concentraci√≥n y Productividad',
        labels={
            'focus_hours': 'Horas de Concentraci√≥n Diarias',
            'productivity': 'Productividad',
            'department': 'Departamento'
        }
    )
    
    focus_flow.update_layout(height=450)
    
    visualizations['focus_flow'] = focus_flow
    
    # 7. Predictor de burnout
    # Top empleados en riesgo
    high_risk = burnout_risk[burnout_risk['burnout_risk_score'] > 60].sort_values('burnout_risk_score', ascending=False)
    
    if len(high_risk) > 0:
        risk_factors = pd.melt(
            high_risk[['employee_id', 'long_hours_factor', 'stress_factor', 'satisfaction_factor', 'balance_factor']],
            id_vars=['employee_id'],
            var_name='factor',
            value_name='score'
        )
        
        # Mapear nombres de factores
        risk_factors['factor'] = risk_factors['factor'].map({
            'long_hours_factor': 'Horas Extendidas',
            'stress_factor': 'Estr√©s Elevado',
            'satisfaction_factor': 'Baja Satisfacci√≥n',
            'balance_factor': 'Desequilibrio Trabajo-Vida'
        })
        
        burnout_prediction = px.bar(
            risk_factors,
            x='score',
            y='employee_id',
            color='factor',
            orientation='h',
            title='Factores de Riesgo de Burnout para Empleados en Alerta',
            labels={
                'employee_id': 'Empleado',
                'score': 'Puntuaci√≥n del Factor',
                'factor': 'Factor de Riesgo'
            }
        )
        
        burnout_prediction.update_layout(
            height=min(100 + len(high_risk) * 30, 600),
            yaxis={'categoryorder':'total ascending'}
        )
        
        visualizations['burnout_prediction'] = burnout_prediction
    
    return visualizations

# Aplicaci√≥n principal
def main():
    # T√≠tulo y descripci√≥n
    st.title("Dashboard de Productividad y Bienestar Laboral")
    st.markdown("""
    Este dashboard analiza la relaci√≥n entre productividad y bienestar laboral, 
    identificando patrones, perfiles de trabajo y factores de riesgo.
    """)
    
    # Sidebar para controles
    st.sidebar.header("Controles")
    
    # Opci√≥n para usar datos generados o cargar propios (simulado)
    data_option = st.sidebar.radio(
        "Fuente de datos:",
        ["Datos simulados", "Cargar mis datos (demo)"]
    )
    
    if data_option == "Datos simulados":
        # Par√°metros para datos generados
        n_employees = st.sidebar.slider("N√∫mero de empleados", 20, 200, 100)
        days = st.sidebar.slider("Per√≠odo de an√°lisis (d√≠as)", 30, 180, 90)
        
        # Generar datos de ejemplo
        with st.spinner("Generando datos de ejemplo..."):
            df = generate_sample_data(n_employees, days)
            st.sidebar.success(f"Datos generados: {len(df)} registros")
    else:
        # Simulaci√≥n de carga de datos
        uploaded_file = st.sidebar.file_uploader("Cargar archivo CSV", type=["csv"])
        
        if uploaded_file is not None:
            # En una implementaci√≥n real, cargar√≠amos el archivo
            # Para demo, usamos datos generados
            with st.spinner("Cargando datos..."):
                df = generate_sample_data(100, 90)
                st.sidebar.success(f"Datos cargados: {len(df)} registros")
        else:
            st.info("Por favor, carga un archivo CSV o selecciona 'Datos simulados'")
            st.stop()
    
    # Filtros para el dashboard
    st.sidebar.header("Filtros")
    
    # Filtro de departamento
    all_departments = sorted(df['department'].unique())
    selected_departments = st.sidebar.multiselect(
        "Departamentos",
        all_departments,
        default=all_departments
    )
    
    # Filtro de fechas
    min_date = df['date'].min()
    max_date = df['date'].max()
    date_range = st.sidebar.date_input(
        "Rango de fechas",
        [min_date, max_date],
        min_value=min_date,
        max_value=max_date
    )
    
    if len(date_range) == 2:
        start_date, end_date = date_range
        filtered_df = df[(df['date'] >= pd.Timestamp(start_date)) & 
                        (df['date'] <= pd.Timestamp(end_date))]
    else:
        filtered_df = df
    
    # Aplicar filtro de departamento
    if selected_departments:
        filtered_df = filtered_df[filtered_df['department'].isin(selected_departments)]
    
    if len(filtered_df) == 0:
        st.warning("No hay datos para los filtros seleccionados. Por favor, ajusta los filtros.")
        st.stop()
    
    # Procesar datos
    with st.spinner("Analizando datos..."):
        # Identificar perfiles de trabajo
        work_profiles, centroids, profile_names = identify_work_profiles(filtered_df)
        
        # Analizar riesgo de burnout
        burnout_risk = analyze_burnout_risk(filtered_df)
        
        # Analizar m√©tricas por departamento
        dept_metrics, dept_trends = analyze_department_metrics(filtered_df)
        
        # Analizar condiciones √≥ptimas
        corr_matrix, productivity_factors, satisfaction_factors = analyze_optimal_conditions(filtered_df)
        
        # Crear visualizaciones
        visualizations = create_dashboard_visualizations(
            filtered_df, work_profiles, burnout_risk, dept_metrics, corr_matrix
        )
    
    # Mostrar KPIs principales
    st.header("Indicadores Clave de Desempe√±o")
    
    # Crear columnas para KPIs
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        avg_productivity = filtered_df['productivity'].mean()
        productivity_trend = np.polyfit(range(len(dept_trends)), dept_trends['productivity'].values, 1)[0] * 30
        
        st.metric(
            "Productividad Promedio",
            f"{avg_productivity:.1f}%",
            f"{productivity_trend:+.1f}% mensual"
        )
    
    with col2:
        avg_satisfaction = filtered_df['satisfaction'].mean()
        satisfaction_trend = np.polyfit(range(len(dept_trends)), dept_trends['satisfaction'].values, 1)[0] * 30
        
        st.metric(
            "Satisfacci√≥n",
            f"{avg_satisfaction:.1f}%",
            f"{satisfaction_trend:+.1f}% mensual"
        )
    
    with col3:
        avg_stress = filtered_df['stress_level'].mean()
        stress_trend = np.polyfit(range(len(dept_trends)), dept_trends['stress_level'].values, 1)[0] * 30
        
        st.metric(
            "Nivel de Estr√©s",
            f"{avg_stress:.1f}%",
            f"{stress_trend:+.1f}% mensual",
            delta_color="inverse"  # Rojo si aumenta
        )
    
    with col4:
        burnout_pct = len(burnout_risk[burnout_risk['burnout_risk_score'] > 60]) / len(burnout_risk) * 100
        
        st.metric(
            "Empleados en Riesgo",
            f"{burnout_pct:.1f}%",
            f"{len(burnout_risk[burnout_risk['burnout_risk_score'] > 60])} empleados"
        )
    
    # Panel de Pesta√±as
    tab1, tab2, tab3, tab4 = st.tabs([
        "Productividad y Bienestar", 
        "Perfiles de Trabajo",
        "Riesgo de Burnout",
        "Recomendaciones"
    ])
    
    # Pesta√±a 1: Productividad y Bienestar
    with tab1:
        st.subheader("Relaci√≥n entre Productividad y Bienestar")
        st.plotly_chart(visualizations['productivity_wellbeing_scatter'], use_container_width=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("M√©tricas por Departamento")
            st.plotly_chart(visualizations['dept_trends'], use_container_width=True)
        
        with col2:
            st.subheader("Correlaci√≥n entre M√©tricas")
            st.pyplot(visualizations['correlation_matrix'])
            
            st.subheader("Impacto de las Horas de Concentraci√≥n")
            st.plotly_chart(visualizations['focus_flow'], use_container_width=True)
    
    # Pesta√±a 2: Perfiles de Trabajo
    with tab2:
        st.subheader("Perfiles de Trabajo Identificados")
        
        # Mostrar informaci√≥n de perfiles
        profile_counts = work_profiles['profile_name'].value_counts()
        
        # Columnas para informaci√≥n general
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.plotly_chart(visualizations['profile_radar'], use_container_width=True)
        
        with col2:
            st.subheader("Distribuci√≥n de Perfiles")
            fig = px.pie(
                values=profile_counts.values,
                names=profile_counts.index,
                title="Distribuci√≥n de Empleados por Perfil"
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # Descripci√≥n detallada de perfiles
        st.subheader("Caracter√≠sticas de los Perfiles")
        
        for profile_name in profile_names.values():
            profile_data = work_profiles[work_profiles['profile_name'] == profile_name]
            dept_distribution = profile_data['department'].value_counts().to_dict()
            
            with st.expander(f"Perfil: {profile_name} ({len(profile_data)} empleados)"):
                col1, col2 = st.columns([3, 2])
                
                with col1:
                    metrics = {
                        'Productividad': f"{profile_data['productivity'].mean():.1f}%",
                        'Horas de Trabajo': f"{profile_data['work_hours'].mean():.1f} horas",
                        'Ratio de Concentraci√≥n': f"{profile_data['focus_ratio'].mean()*100:.1f}%",
                        'Estr√©s': f"{profile_data['stress_level'].mean():.1f}%",
                        'Satisfacci√≥n': f"{profile_data['satisfaction'].mean():.1f}%",
                        'Equilibrio Trabajo-Vida': f"{profile_data['work_life_balance'].mean():.1f}%"
                    }
                    
                    for metric, value in metrics.items():
                        st.text(f"{metric}: {value}")
                
                with col2:
                    st.text("Distribuci√≥n por Departamento:")
                    for dept, count in dept_distribution.items():
                        st.text(f"- {dept}: {count} empleados ({count/len(profile_data)*100:.1f}%)")
    
    # Pesta√±a 3: Riesgo de Burnout
    with tab3:
        st.subheader("An√°lisis de Riesgo de Burnout")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.plotly_chart(visualizations['burnout_heatmap'], use_container_width=True)
        
        with col2:
            # Distribuci√≥n por nivel de riesgo
            risk_distribution = burnout_risk['burnout_risk'].value_counts().reset_index()
            risk_distribution.columns = ['risk_level', 'count']
            
            # Ordenar por nivel de riesgo
            risk_order = {'Bajo': 0, 'Moderado': 1, 'Alto': 2, 'Cr√≠tico': 3}
            risk_distribution['order'] = risk_distribution['risk_level'].map(risk_order)
            risk_distribution = risk_distribution.sort_values('order')
            
            risk_colors = {
                'Bajo': 'green',
                'Moderado': 'yellow',
                'Alto': 'orange',
                'Cr√≠tico': 'red'
            }
            
            fig = px.pie(
                risk_distribution,
                values='count',
                names='risk_level',
                title="Distribuci√≥n de Niveles de Riesgo",
                color='risk_level',
                color_discrete_map=risk_colors
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
        # Factores contribuyentes
        if 'burnout_prediction' in visualizations:
            st.subheader("Factores de Riesgo para Empleados en Alerta")
            st.plotly_chart(visualizations['burnout_prediction'], use_container_width=True)
        
        # Tabla de empleados de alto riesgo
        st.subheader("Empleados con Mayor Riesgo")
        high_risk = burnout_risk[burnout_risk['burnout_risk_score'] > 60].sort_values('burnout_risk_score', ascending=False)
        
        if len(high_risk) > 0:
            high_risk_table = high_risk[['employee_id', 'department', 'role', 'burnout_risk_score', 'burnout_risk', 'primary_factor']].copy()
            high_risk_table.columns = ['ID', 'Departamento', 'Rol', 'Puntuaci√≥n', 'Nivel de Riesgo', 'Factor Principal']
            
            # Formatear puntuaci√≥n
            high_risk_table['Puntuaci√≥n'] = high_risk_table['Puntuaci√≥n'].round(1)
            
            st.dataframe(high_risk_table, use_container_width=True)
        else:
            st.info("No se encontraron empleados con alto riesgo de burnout.")
    
    # Pesta√±a 4: Recomendaciones
    with tab4:
        st.subheader("Condiciones √ìptimas para Productividad")
        
        prod_recommendations = pd.DataFrame(productivity_factors)
        
        st.write("""
        Seg√∫n nuestro an√°lisis, estas son las condiciones que muestran la mayor
        correlaci√≥n con altos niveles de productividad:
        """)
        
        for _, row in prod_recommendations.iterrows():
            factor = row['factor']
            corr = row['correlation']
            opt_range = row['optimal_range']
            
            corr_str = f"{corr:.2f}"
            corr_desc = "positiva fuerte" if corr > 0.7 else "positiva moderada" if corr > 0.3 else \
                       "positiva d√©bil" if corr > 0 else "negativa d√©bil" if corr > -0.3 else \
                       "negativa moderada" if corr > -0.7 else "negativa fuerte"
            
            st.markdown(f"**{factor}** (correlaci√≥n {corr_str}, {corr_desc})")
            st.markdown(f"Rango √≥ptimo: **{opt_range}**")
            st.markdown("---")
        
        st.subheader("Mejoras Recomendadas por Departamento")
        
        # Generar recomendaciones personalizadas por departamento
        for dept in selected_departments:
            dept_data = dept_metrics[dept_metrics['department'] == dept].iloc[0]
            
            with st.expander(f"Recomendaciones para: {dept}"):
                st.markdown(f"**Situaci√≥n Actual:**")
                st.markdown(f"- Productividad: {dept_data['productivity']:.1f}%")
                st.markdown(f"- Satisfacci√≥n: {dept_data['satisfaction']:.1f}%")
                st.markdown(f"- Nivel de Estr√©s: {dept_data['stress_level']:.1f}%")
                st.markdown(f"- Horas de Trabajo: {dept_data['work_hours']:.1f} horas")
                st.markdown(f"- Horas de Reuniones: {dept_data['meeting_hours']:.1f} horas ({dept_data['meeting_ratio']*100:.1f}% del tiempo)")
                
                st.markdown("**Recomendaciones Principales:**")
                
                # Recomendaciones basadas en m√©tricas
                if dept_data['meeting_ratio'] > 0.25:
                    st.markdown("üîπ **Reducir tiempo en reuniones:** El departamento pasa un porcentaje elevado del tiempo en reuniones, lo que podr√≠a estar afectando la productividad. Considere implementar reuniones m√°s cortas y eficientes.")
                
                if dept_data['focus_ratio'] < 0.6:
                    st.markdown("üîπ **Aumentar tiempo de concentraci√≥n:** El tiempo dedicado a trabajo concentrado es bajo. Considere implementar bloques de tiempo sin interrupciones o pol√≠ticas de 'no reuniones' en ciertos d√≠as.")
                
                if dept_data['stress_level'] > 60:
                    st.markdown("üîπ **Gestionar niveles de estr√©s:** Los niveles de estr√©s son elevados. Considere revisar la carga de trabajo, plazos y expectativas.")
                
                if dept_data['work_hours'] > 8.5:
                    st.markdown("üîπ **Evaluar carga horaria:** Las horas de trabajo est√°n por encima del √≥ptimo. Revisar si hay ineficiencias en procesos o distribuci√≥n de tareas.")
                
                if dept_data['satisfaction'] < 65:
                    st.markdown("üîπ **Mejorar satisfacci√≥n laboral:** Los niveles de satisfacci√≥n est√°n por debajo del √≥ptimo. Considere realizar entrevistas individuales para identificar √°reas de mejora.")
                
                # A√±adir siempre al menos una recomendaci√≥n
                if not (dept_data['meeting_ratio'] > 0.25 or dept_data['focus_ratio'] < 0.6 or 
                       dept_data['stress_level'] > 60 or dept_data['work_hours'] > 8.5 or 
                       dept_data['satisfaction'] < 65):
                    st.markdown("üîπ **Mantener pr√°cticas actuales:** Las m√©tricas del departamento son generalmente positivas. Considere documentar y compartir buenas pr√°cticas con otros equipos.")
        
        st.subheader("Plan de Acci√≥n Recomendado")
        st.markdown("""
        Basado en todos los datos analizados, recomendamos el siguiente plan de acci√≥n:
        
        1. **Implementar bloques de concentraci√≥n:** Designar per√≠odos espec√≠ficos (m√≠nimo 2 horas diarias) sin reuniones o interrupciones para trabajo concentrado.
        
        2. **Revisar pol√≠ticas de reuniones:** Limitar reuniones a m√°ximo 25% del tiempo laboral, con agendas claras y duraciones acotadas.
        
        3. **Implementar programa de bienestar:** Sesiones de mindfulness, gesti√≥n de estr√©s y promoci√≥n de pausas activas.
        
        4. **Feedback continuo:** Encuestas breves semanales de pulso para monitorear satisfacci√≥n y bienestar.
        
        5. **Formaci√≥n en gesti√≥n del tiempo:** Capacitaci√≥n espec√≠fica para empleados con patrones de trabajo que muestran riesgos.
        
        6. **Revisi√≥n de carga de trabajo:** Especialmente para departamentos con niveles de estr√©s elevados o tendencias negativas.
        """)
        
        # M√©tricas sugeridas para seguimiento
        st.subheader("M√©tricas de Seguimiento Recomendadas")
        
        metrics_col1, metrics_col2 = st.columns(2)
        
        with metrics_col1:
            st.markdown("""
            **M√©tricas de Productividad:**
            - Ratio de tiempo concentrado vs tiempo total
            - Tiempo efectivo en reuniones
            - Tasa de cumplimiento de plazos
            - Calidad de entregables (revisi√≥n por pares)
            - Velocidad de resoluci√≥n de incidencias
            """)
        
        with metrics_col2:
            st.markdown("""
            **M√©tricas de Bienestar:**
            - Pulso semanal de satisfacci√≥n
            - Autoinforme de nivel de estr√©s
            - Equilibrio percibido trabajo-vida
            - Tasa de incidentes de salud relacionados con estr√©s
            - Participaci√≥n en programas de bienestar
            """)
    
    # Secci√≥n final: Insights y conclusiones
    st.header("Insights Principales")
    
    # Obtener algunos insights autom√°ticos basados en los datos
    insights = []
    
    # Insight 1: Relaci√≥n productividad-concentraci√≥n
    focus_prod_corr = np.corrcoef(
        df.groupby('employee_id')['focus_hours'].mean(),
        df.groupby('employee_id')['productivity'].mean()
    )[0, 1]
    
    if focus_prod_corr > 0.5:
        insights.append(
            "Existe una fuerte correlaci√≥n positiva entre el tiempo de concentraci√≥n y la productividad. "
            f"Por cada hora adicional de trabajo concentrado, la productividad aumenta aproximadamente "
            f"{work_profiles['productivity'].corr(work_profiles['focus_hours']) * 10:.1f} puntos."
        )
    
    # Insight 2: Perfil m√°s productivo
    top_profile = work_profiles.groupby('profile_name')['productivity'].mean().idxmax()
    top_profile_data = work_profiles[work_profiles['profile_name'] == top_profile]
    
    insights.append(
        f"El perfil de trabajo '{top_profile}' muestra la mayor productividad promedio "
        f"({top_profile_data['productivity'].mean():.1f}%), combinando un equilibrio de "
        f"{top_profile_data['work_hours'].mean():.1f} horas de trabajo con un ratio de concentraci√≥n del "
        f"{top_profile_data['focus_ratio'].mean()*100:.1f}%."
    )
    
    # Insight 3: Riesgo de burnout
    if len(burnout_risk[burnout_risk['burnout_risk_score'] > 60]) > 0:
        high_risk_dept = burnout_risk.groupby('department')['burnout_risk_score'].mean().idxmax()
        insights.append(
            f"El departamento de {high_risk_dept} muestra el mayor riesgo de burnout, con un "
            f"{len(burnout_risk[(burnout_risk['department'] == high_risk_dept) & (burnout_risk['burnout_risk_score'] > 60)])} "
            f"empleados en niveles de riesgo alto o cr√≠tico. El factor principal es "
            f"{burnout_risk[burnout_risk['department'] == high_risk_dept]['primary_factor'].mode()[0]}."
        )
    
    # Insight 4: Tendencias
    improving_dept = dept_metrics[dept_metrics['satisfaction_trend'] > 0]['department'].values
    if len(improving_dept) > 0:
        insights.append(
            f"Los departamentos {', '.join(improving_dept)} muestran tendencias positivas "
            f"en satisfacci√≥n, lo que sugiere que las iniciativas recientes est√°n teniendo un impacto positivo."
        )
    
    # Mostrar insights
    for i, insight in enumerate(insights, 1):
        st.info(f"**Insight {i}:** {insight}")
    
    # Pie de p√°gina
    st.markdown("---")
    st.markdown(
        "Dashboard desarrollado por Naiara Rodr√≠guez - Data Analytics Portfolio"
    )

if __name__ == "__main__":
    main()